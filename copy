import pandas as pd

# 1. Your initial DataFrame, now with more metadata columns
data = {
    'document_id': ['doc_A_01', 'doc_B_02'],
    'author': ['Alice', 'Bob'],
    'case_name': ['WorldCom Litigation', 'Enron Case'],
    'citation_date': ['2004-07-01', '2006-05-25'],
    'embeddings_data': [
        {
            "embedding_text": ['This is chunk 1.', 'This is chunk 2.'],
            "embedding_vector": [[0.1, 0.2], [0.3, 0.4]]
        },
        {
            "embedding_text": ['Another document, first part.', 'Another document, second part.'],
            "embedding_vector": [[0.7, 0.8], [0.9, 1.0]]
        }
    ]
}
df_initial = pd.DataFrame(data)

print("--- 1. Initial DataFrame with Multiple Metadata Columns ---")
print(df_initial)


# 2. The Scalable Transformation Logic
all_nodes_data = []

# The column containing the dictionary to be unpacked
dict_column_name = 'embeddings_data'

for index, row in df_initial.iterrows():
    # --- THIS IS THE KEY CHANGE ---
    # Create a base dictionary of the row's original data,
    # EXCLUDING the column we are about to unpack.
    base_data = row.drop(dict_column_name).to_dict()
    
    # Get the dictionary containing the parallel lists
    data_dict = row[dict_column_name]
    
    texts = data_dict.get('embedding_text', [])
    vectors = data_dict.get('embedding_vector', [])
    
    # Loop through the parallel lists
    for i, (text, vector) in enumerate(zip(texts, vectors)):
        # Start with a copy of the original row's data
        new_row = base_data.copy()
        
        # Generate the new, unique primary key for this node
        node_id = f"{base_data['document_id']}_node_{i}"
        
        # Add the new, unpacked data to this specific row
        new_row['node_id'] = node_id
        new_row['text_chunk'] = text
        new_row['vector'] = vector
        
        all_nodes_data.append(new_row)

# 3. Create the final DataFrame
df_final = pd.DataFrame(all_nodes_data)

print("\n--- 2. Final DataFrame with ALL Original Columns Preserved ---")
print(df_final)
